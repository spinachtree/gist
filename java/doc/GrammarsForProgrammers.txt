
title	Grammars for Programmers

sect	Introduction

Grammar rules have a long tradition as formal specifications, but it is not always easy for a programmer to implement a parser for a given grammar. This note shows how grammar rules can be automated and directly linked into methods or functions in an application programming language.

A quick example illustrates how this works. Although this particular example is written in Ruby you should be able to see how it works even without any prior knowledge of Ruby. A Java version of the #Java[same example] is shown in the end notes.

eg
	# Calculator Example =====================================================

	# Takes an input text string with arithmetic, such as: "1+2+3*(3-4/2+1)-3"
	# and calculates the result, in this case 6.

	class Calculate
	
		# Syntax: the grammar for the input text....

		Grammar = "
			arith = term (add term)*
			term  = val (mult val)*
			val   = num | '(' arith ')'
			add   = '+' | '-'
			mult  = '*' | '/'
			num   = '0'..'9'+
		"

		# Semantics: calculator rule transform methods.....

		def arith(x, op=nil, y=nil, *etc)
			return x unless op
			arith(calc(x,op,y), *etc)
		end

		def term(*args)
			arith(*args)
		end
	
		def val(x)
			return x if x.is_a? Numeric  # arith
			x.to_i # num, convert it to numeric..
		end

		# support method ---------------

		def calc(n,op,m)
			case op
				when '+' then n+m
				when '-' then n-m
				when '*' then n*m
				when '/' then n/m
			end
		end

	end #Calculate

	# -- run an example -----------
	
	require 'Gist'

	example="1+2+3*(3-4/2+1)-3"

	calc = Gist.new(Calculate)
	result = calc.transform(example)

	puts "%s = %d" %[example,result]

The idea is to map from grammar rules directly into methods in your programming language (in this example Ruby methods). Each grammar rule that matched the input string will invoke a method with the same name. Not every grammar rule needs a corresponding method, the text string matched by the grammar rule will be used by default. In this example the .eg[add], .eg[mult] and .eg[num] rules each generate a string match by default.

The example simply prints .eg[1+2+3*(3-4/2+1)-3 = 6], but you can probably already see ways to expand on this example, and how to use a similar approach in your own applications. The semantic methods may compute any sort of result, it may be a simple value, as in the Calculate example, or the methods may construct a custom syntax tree for an application to work with.

The grammar is a formal specification that is independent of the programming language. The semantic methods shown here use Ruby (or #Java), and the details of argument processing will vary in other programming languages. The same model can be implemented in almost any programming language, the grammar specification can map input strings into whatever methods, functions, procedures or pattern unification mechanisms are available in the programming language.

The key machinery is a #generic-parser that can execute the grammar rules. The .eg[Gist] class provides the parser and links the grammar rules into your application methods. To write your own methods you need to know how the grammar expressions are mapped into your method arguments, but that's about it.


sect	Related Techniques

The #TXL language is a unique programming language that automates grammar rules together with transform rules. The techniques discussed in this note are a simple subset of the facilities provided in TXL. Rather than using a special purpose language to automate grammar rules we are extending a general purpose programming language with the ability to employ grammar rules.

The logic programming language Prolog provides somewhat similar capabilities by using a Definite Clause Grammar DCG. Haskel and Scala are examples of languages that provide a parser combinator library to enable grammars to be implemented, and they have pattern matching rules that can be used for semantic methods. We are using a simpler Committed Choice #CCG grammar (to be discussed shortly) to enable the grammar specification to be directly interpreted without the need for functional combinators.

A popular option is to use a #parser-generator to create a parser from the grammar rules. The parser typically builds a parse tree data structure that the application program navigates to process the input text. There may also be a Document Object Model to provide an application programming interface into the parse tree. The approach used here hides the parse tree by linking the grammar rule into semantic methods, and one option is to have these semantic methods build a application specific parse tree for the rest of the application to process.

Some parsers allow semantic methods to be invoked directly from the grammar rules, or methods may be triggered by an event driven parser. This is not the same as the approach discussed here. Here we only invoke the semantic methods after the parser has completely parsed the input. If a semantic method is invoked immediately from a grammar rule there is a possibility that the parse may later fail, and retreat back to match the same text with some other rules.

For a hand coded parser a top down recursive descent parser has the advantage of following the structure of the grammar rules. The simpler #CCG grammar rules used here allow a top down parser to be automated with grammar driven #generic-parser.


sect	Grammar Languages

A careful choice of grammar rules can simplify the task of writing a parser program. A traditional choice has been a Context Free Grammar, or #CFG, but the automation of a CFG is still quite difficult. We focus here on a simpler kind of grammar, a Committed Choice Grammar, or #CCG.

A CCG has one big restriction, it excludes ambiguity, the grammar rules can match an input in only one way. A traditional CFG can easily specify ambiguities that occur in a natural human language, but a CCG can not. On the other hand, ambiguity in a computer language is a defect that we want to eradicate, so a CCG is a good fit for computer applications. A CCG is easy to parse, in effect we can execute the grammar rules directly as a parser. This enables a generic parser that can automatically interpret any CCG grammar we choose to write.

The expressive power of a grammar is judged by the languages that it can express. It is not possible to directly compare the power of a CCG with the power of a traditional CFG: there are ambiguous languages that a CFG can define that are beyond a CCG, and there are languages that a CCG can define that are beyond a CFG (i.e. a CCG can define some context sensitive languages). The good news is that for unambiguous computer languages a CCG is a very effective replacement for a traditional CFG. A #PEG (Parser Expression Grammar) is a well defined subset of a CCG.

So here's the road map: first we need a way to express our CCG grammar, that is called #[PBNF!], or Parser-BNF!, a version of the classic #BNF grammar rules (using BNF! flags the committed-choice interpretation). The second thing we need is an implementation of a #generic-parser for the PBNF! rules. You will need a version implemented for your particular programming language, or a #Gist kit-set for implementing your own version.

If you are familiar with grammar specifications and parser generators then please don't assume too much. A CCG is simpler than a traditional CFG grammar, it is much closer to a PEG. More on this shortly.


sect	PBNF! Grammar Rules

Each PBNF! grammar rule names a committed choice grammar expression:

eg
	R = expression

The grammar expression may be any combination of:

eg
	x | y		-- a choice that selects the longest match of x or y
	x , y		-- a sequence of x followed by y (the comma is optional except at a line break)
	x*		-- repeat x as many times as possible (including zero)
	x+		-- one or more x, syntactic sugar for: x x*
	x?		-- optional x, matches an x if it can: (x|'')
	!x		-- not x predicate, matches nothing, but fails if x could be matched.
	&x		-- is x predicate, same as !!x (look ahead and fail unless an x could be matched)
	(x y)		-- grouping a sub-expression into a term
	'a'		-- literal character match
	'a'..'f'	-- matches a character in the given range
	42		-- matches a character with this numeric character code value
	48..57		-- matches a character in this range of numeric character code values

This is a basic set of PBNF! expressions, sufficient to represent a #PEG. A full #[PBNF!] defines additional grammar notations and special grammar operators for context sensitive languages.

The x and y in these expressions can be any grammar expression. The precedence increases from the top of this list to the bottom, so that:

eg
	x y | y 48..57+		is interpreted as:	(x, y) | (y, (48..57)+)

The PBNF! rules look like traditional grammar rules (with some extra operators), and the rules usually match in exactly the same way. But PBNF! rules are committed choice rules, the longest match (or the prescribed unique match) is the only acceptable match.


sect	Committed Choice Rules

A traditional #CFG can be expressed with a version of #BNF rules such as:

eg
	number ::= digit+
	digit  ::= '0'..'9'

This seems simple enough, a natural number is one or more digit. The same thing can also be expressed as a digit followed by any number of digits:

eg
	number  ::= digit digit*

Or, yet again, as a digit OR a digit followed by a number:

eg
	number  ::= digit | digit number

But this is ~not what I meant to say. I want a number to be represented by a string of digits, ~all the digits, not just some of them. I really intended to say:

eg
	number  ::= digits !digit
	digits  ::= digit | digit digits

The :[!digit] is necessary to ensure that the number rule can not match just some of the digits. In fact this may not be possible with a traditional CFG that does not have negation. The other definitions need to be corrected in the same way:

eg
	number  ::= digit+ !digit  -- only the longest match

In an unambiguous grammar this is the required interpretation. We do not want elements such as numbers, words, names or other items to be sub-divided, the longest match is the only meaningful match. A traditional grammar rule will accept that a name like :foobar can match in 6 possible ways (giving a possible set of 720 names), but in practice for an unambiguous language that is not what is wanted at all, it should match a name in only one way. If we want to match say :[foo] followed by :[bar] then we would write :[foo-bar] or :[foo bar], or we would use a more pedantic grammar to say exactly how a name string may be sub-divided without ambiguity.

At first sight the PBNF! rules appear to be the same as traditional rules, we simply use .eg[=] instead of .eg[::=], but the PBNF! grammar uses a committed choice interpretation. A PBNF! rule will only match in one unique way (such as the longest choice), whereas a traditional CFG interpretation includes multiple possible matches (shorter than the longest match). Note that some versions of BNF, such as EBNF, also use :[=] in place of :[::=], but EBNF uses the traditional CFG interpretation.

Because a PBNF! grammar ~only matches the longest choice we can simply say:

eg
	number = digit+

There is no need to add the :[!digit], this is implicit in the CCG interpretation. After all, the longest match of one or more digit would not be the longest match if it was followed by another digit.

Another example. This traditional CFG grammar rule will match :[abc]:

eg
	s ::= ('a' | 'ab') 'bc'  -- matches "abc", or "abbc"

But the equivalent committed choice PBNF! rule will not match :[abc]:

eg
	s = ('a' | 'ab') 'bc'  -- matches "abbc" but not "abc"

If the input starts with :[ab] then the longest match committed choice will exclude the possibility of matching the input :[abc]. The committed choice restricts the expressive power of the grammar by excluding ambiguity. For computer languages this works well, and the choices are mutually exclusive by design. When all the choices are mutually exclusive then a committed choice grammar has an identical interpretation to a traditional grammar.

In a committed choice grammar we need to be wary of choices that are not mutually exclusive, usually they are a mistake and should be rewritten to clarify the intent. For the previous example it could be:

eg
	s = 'ab' ('bc' | 'c')  -- matches "abc" or "abbc"

The difference between a CCG and a traditional CFG is more likely to appear with the repeat operator, for example:

eg
	enz ::= digit* '0'  -- a number that ends with a zero

This traditional grammar :enz rule matches the longest string of digits that ends with a :[0] (which may include other :[0]'s), but any following digits will remain unmatched.

But as a CCG the :enz rule will always fail since the :[digit*] will match the longest sequence of digits, so there can never be a subsequent :[0]. Instead we need to use a more pedantic rule:

eg
	enz  = (nz* '0')*  -- any number of non-zero digits followed by '0', any number of times
	nz   = '1'..'9'

Negation can simplify cases like this, but for an unambiguous grammar the requirement for a prefix match is surprisingly rare.

Some of us have become accustomed to sloppy prefix matching with regular expressions. For example, to match the last item or character we just match everything (with .eg[.*]), followed by a last item; the regular expression engine will back off to match the last item if it can. To be pedantic, and efficient, we should only match characters that do not consume the last item, but the sloppy version is very convenient. A CCG does not afford the luxury of a sloppy prefix match, we must be more pedantic.

For example, to match a list of one or more dot separated names:

eg
	names = first ('.' mid &'.')* ('.' last)?

A CCG is usually exactly what we want (with mutually exclusive choices), but sometimes the grammar must be expanded to spell out all the acceptable choices without ambiguity. In practice, for unambiguous computer languages, CCG rules provide a very neat fit.


sect	Pattern Matching Rules

The PBNF! grammar rules act as pattern matching rules that map the syntax of input text into argument values for your semantic methods. You define a method for a grammar rule by using the same name, and the parameters must match rule references as they appear in the right hand side of the grammar rule. Literal matches can not appear as parameters. For example, the .eg[val] rule in the Calculate example is defined as:

eg
	val   = num | '(' arith ')'

So a .eg[val] can match a .eg[num] or an .eg[arith], which is a a single parameter in your semantic method. The literals, .eg['('] and .eg[')'], can not be parameters (unless you add new rules to the grammar). A semantic method for the .eg[val] rule is therefore defined with one parameter:

eg
	def val(x)  .... # x is a num or an arith result

When the .eg[val] rule matches a .eg[num] then the argument will be a string that can be converted into a Ruby numeric value (using the standard .eg[.to_i] method). When the .eg[val] rule matches an .eg[arith] rule then the argument value will be the numeric result from the .eg[arith] method. Hence the semantic method:

eg
	def val(x)
		return x if x.is_a? Numeric
		x.to_i  # convert a num to a Numeric int
	end

The :arith grammar rule is defined as:

eg
	arith = term (add term)*

So the :arith method must be able to match a list of arguments. When the rule matches a single :term there is only one argument value, and the :arith method can simply return the result that the :term method has computed. Otherwise it calculates the value of the first three arguments, and tries again with this result followed by any remaining arguments.

It could be written as:

eg
	def arith(*args) # args <= term (add term)*
		return args[0] if args.length == 1 # single term result
		x = args[0]  # term 
		op = args[1] # add
		y = args[2]  # term
		z = calc(x,op,y) # (term op term)
		arith(z, *args[3..-1])
	end

This can be expressed more succinctly as:

eg
	def arith(x, op=nil, y=nil, *etc)
		return x unless op
		arith(calc(x,op,y), *etc)
	end


sect	Pragmatic Rule Annotations

This section introduces optional annotations that help to express the design intent of the grammar rules. There is nothing fundamentally new here, and you may choose to skip this section.

sub	Literal Definitions

Let's extend our Calculate grammar to allow white-space in the arithmetic:  

eg
	arith = s term (s add s term)* s
	term  = val (s mult s val)*
	val   = num | '(' arith ')'
	add   = '+' | '-'
	mult  = '*' | '/'
	num   = '0'..'9'+
	s     = (9 | 10 | 13 | ' ')*

In this case we want to allow any white-space characters (tab, space, new lines). This is quite common, but there are some grammars that depend on line breaks and indentation, so white-space can not always be simply ignored. There are various ways to specify white space in a grammar, this example is just one possibility.

In this case we are not really interested in the white-space, and we don't want it to appear as extra irrelevant arguments in our semantic methods. Imagine for a moment that we could accept only simple space characters, then we could have written:

eg
	arith = ' '* term (' '* add ' '* term)* ' '*
	term  = val (' '* mult ' '* val)*
	val   = num | '(' arith ')'
	add   = '+' | '-'
	mult  = '*' | '/'
	num   = '0'..'9'+

It's messy and inadequate but notice that the white-space will no longer appear as arguments to the semantic methods.

So we want to match the space rule as if it is a literal expression. Using the prefix :[`s] does just that:

eg
	arith = `s term (`s add `s term)* `s
	term  = val (`s mult `s val)*
	val   = num | '(' arith ')'
	add   = '+' | '-'
	mult  = '*' | '/'
	num   = '0'..'9'+
	s     = (9 | 10 | 13 | ' ')*

Since the reference :[`s] acts as a literal match it will never appear as a method argument.

sub	Terminal Rules

It is common for a grammar to have about half the rules used to express terminal string matches, as against composite rules that contain internal structure with elements that reference other rules. By examining the grammar expression we can determine if a rule is a terminal string matching rule, but sometimes it is better to use an explicit annotation to make this clear to the reader. For example, consider a rule to match a hex digit:

eg
	hex = digit | 'a'..'f' | 'A'..'F'

It is not likely that we want to distinguish hex values that contain decimal digits from hex values that only contain letters. We probably intended this rule to simply express the range of acceptable characters:

eg
	hex = '0'..'9' | 'a'..'f' | 'A'..'F'

We can indicate this by using :[`digit] to match as a literal, but it is often better to designate the rule as a terminal rule where the whole grammar expression is a literal match with no internal structure.

The terminal rule annotations makes the design intent explicit: just change the :[=] to a :[:], the syntax definition will not change at all, but we now know at a glance that the rule is a terminal rule, and it will match a string value:

eg
	hex : digit | 'a'..'f' | 'A'..'F'

In summary: literal references and the terminal rules make no difference to the syntax that the grammar rules define. But not all grammar rules have the same semantic significance. The literal prefix is used to clarify the grammar rules by designating elements that are not considered significant to the semantics (they are not needed as method arguments). Similarly if a rule is designated as a terminal rule it makes it clear that the rule is designed to match a string and there is no internal structure that has any semantic interest.

It is easy to think that a grammar is only concerned with syntax, but consider these two rules:

eg
	date = month '/' day

as against:

eg
	date = day '/' month

The syntax is identical, but the semantic intent is quite different, and the rule names are significant. The semantic design intent of the grammar rules is an important dimension. Literal references and explicit terminal rules help to clarify the design intent. They indicate the semantic significance of the syntax rules.


sect	Conclusions

A grammar provides a powerful succinct formal specification. But traditional grammars are difficult to deal with. There are lots of good #parser-generator tools, but it is not usually a fully automated process. A custom parser is usually generated for a specific grammar, and this generates a parse tree data structure. The application program then navigates the parse tree to process the parsed input text.

This note shows how a grammar can be linked directly into semantic methods or functions in an application program. This simplifies the interface between the grammar/parser and application by eliminating the need for an explicit parse tree or some form of document object model DOM interface. The semantic methods are not invoked from an event driven parser, the methods are only invoked after grammar elements are completely parsed.

It is possible to link any kind of grammar rules into semantic methods, but it is difficult to fully automate an efficient parser for a traditional #CFG, and some languages can not be fully expressed as a CFG. For computer languages that eliminate ambiguity it is possible to use a Committed Choice Grammar #CCG. A CCG enables a #generic-parser that can fully automate any CCG, and it can also express some useful context sensitive grammars that are beyond a traditional CFG.

The end result is an effective method to fully automate a grammar. Formal grammar specifications can be used without change, and they can be directly interpreted in an application program that may be written in almost any programming language.


sect#end	End Notes

sub#Java	A Java version of the Calculator example:

eg
	import org.spinachtree.gist.Gist;

	// Usage:
	//	Calculator myCalc=new Calculator();
	//	int result=new Calculator().eval("1+2+3*(3-4/2+1)-3");

	public class Calculator {

		public final String calcGrammar = 
		"	arith = term (add term)*		\n"+
		"	term  = val (mult val)*			\n"+
		"	val   = num | '(' arith ')'		\n"+
		"	add   : '+' | '-'			\n"+
		"	mult  : '*' | '/'			\n"+
		"	num   : '0'..'9'+			";
		
		private Gist calc;
	
		public Calculator() {
			// create Gist transformer with grammar and rule listener..
			calc=new Gist(calcGrammar,this);
		}
	
		public int eval(String expression) {
			return ((Integer)calc.transform(expression));
		}

		// --- transform method for calcGrammar -----------------------------
	
		public Integer arith(Object[] args) {
			if (args.length==1) return (Integer)args[0];
			return reduce((Integer)args[0],1,args);
		}
	
		public Integer term(Object[] args) {
			return arith(args);
		}
	
		public Integer val(Object[] args) {
			Object x=args[0];
			if (x instanceof String) return new Integer((String)x);
			return (Integer)x;
		}

		// --- end transform method for calcGrammar -----------------------------

		Integer reduce(int x, int i, Object[] args) {
			if (i>=args.length) return x;
			String op = (String)args[i];
			int y = (Integer)args[i+1];
			return reduce(calc(x,op,y),i+2,args);
		}
		
		int calc(int x, String op, int y) {
			if (op.equals("+")) return (x+y);
			if (op.equals("-")) return (x-y);
			if (op.equals("*")) return (x*y);
			if (op.equals("/")) return (x/y);
			return 0; // should throw exception
		}
		
		public static void main(String[] args) {
			String input="2+5*8";
			if (args.length>0) input=args[0];
			Integer ans=new Calculator().eval(input);
			System.out.printf("%s => %s %n",input,ans.intValue());
		}

	} // Calcualator


sub#BNF		BNF Backus-Naur Form

Backus-Naur Form (or Backus-Normal Form) is the traditional notation to express a Context Free Grammar #CFG for computer language specifications. BNF was developed in the 1950's and used to define Algol-60. The notation has evolved and there are several variants, such as EBNF (and a different EBNF used to define XML) and ABNF used to define many IETF RFC internet specifications.

@[http://en.wikipedia.org/wiki/Backus–Naur_Form] 


sub#BNF!	BNF! is BNF interpreted as a CCG

The ! suffix is used to flag the fact that the BNF is interpreted as a CCG rather than a traditional CFG.


sub#CFG		CFG Context Free Grammar

The formal grammar specifications for programming languages are traditionally based on a CFG expressed in some form of BNF. Regular expressions are a subset (ie can express a subset of the languages) of a CFG, and a CFG is a subset of context sensitive grammars which are a subset of unrestricted grammars that can express anything that a Turing machine can compute.

@[http://en.wikipedia.org/wiki/Context-free_grammar]


sub#CCG		CCG Committed Choice Grammar.

In a CCG every grammar operator (choice, repeat, etc) must make a committed choice to a unique match for any given input string, or fail. This excludes ambiguity. A Parser Expression Grammar #PEG is a formally defined example of a CCG.

A traditional #CFG allows grammar operators to have multiple ways to match an input, but when a CFG is used to define an unambiguous language the possibility of multiple matches are almost always extraneous and incorrect. Because a CCG eliminates multiple choices (and the rules act as functions) a CCG grammar is closed under composition, but a traditional CFG is not.

A CFG can express an ambiguous language while a CCG can not, but a CCG can have grammar operators such as negation and others that allows a CCG to express context sensitive languages that are beyond a CFG.


sub#generic-parser	Generic Parser

A generic parser, or grammar driven parser, can take any grammar and automatically act as a parser for that grammar. The grammar rules may be interpreted as parser instructions, or instructions for a parser machine can be compiled from the grammar rules. A fully automated generic parser is difficult to construct for a traditional #CFG, and a #parser-generator is often used. But a #PEG or #CCG enables a fully automated generic parser using a top down recursive descent parser.


sub#Gist	Gist, a kit-set PBNF! parser

Gist is a kit-set implementation of a #[PBNF!] parser that has been implemented in several different programming languages. The kit-set starts with a bootstrap parser that can be expanded into a full PBNF!. The #generic-parser is quite portable, but the ways the grammar rules are linked into the methods or functions of a programming language must be tailored to the particular features of the programming language.

To implement in your own language. ... TODO a Ruby and Java example to be provided, at least...

sub#parser-generator	Parser Generators

A parser for a simple grammar may be programmed by hand, and some programming languages provide features that support more elaborate parsers, for example #TXL, Prolog, or combinators in Haskel or Scala. Otherwise a parser generator can be used. There is a long history of parser generators or compiler-compilers, starting with Yacc. @[http://www.antlr.org/][Antlr] is a good example of a modern parser generator together with grammar design and testing tools.

It is much easier to hand code a parser for a #CCG or #PEG grammar since these grammars can be directly implemented with a top-down recursive descent parser. These grammars can be automated with a #generic-parser.


sub#PBNF!	PBNF! Parser-BNF!

Parser-BNF! is a form of #[BNF!] which uses traditional BNF notation to represent a #CCG. Ambiguity is eliminated in every grammar expression, so the interpretation of PBNF! is deterministic.

TODO ref to full specification of the PBNF! language


sub#PEG		PEG Parser Expression Grammar

PEG provides a specific example of a #CCG with has a @[http://pdos.csail.mit.edu/~baford/packrat/popl04/][formal specification] that was published by Bryan Ford in 2004. It has generated interest as a simpler way to define a grammar that enables an efficient @[http://pdos.csail.mit.edu/~baford/packrat/thesis/][linear time parser].

More on PEG: @[http://pdos.csail.mit.edu/~baford/packrat/]


sub#TXL		The TXL language

TXL @[http://www.txl.ca/] is a special purpose language language designed for processing grammar rules and transform rules. The grammar rules can be ambiguous and the transform rules can control and transform the terms defined by the grammar rules.


